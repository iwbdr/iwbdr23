---
layout: default
---



# Introduction

Today's modern applications are producing too large volumes of data to be stored, processed, or transferred efficiently. Data reduction is becoming an indispensable technique in many domains because it can offer a great capability to reduce the data size by one or even two orders of magnitude, significantly saving the memory/storage space, mitigating the I/O burden, reducing communication time, and improving the energy/power efficiency in various parallel and distributed environments, such as high-performance computing (HPC), cloud computing, edge computing, and Internet-of-Things (IoT). An HPC system, for instance, is expected to have a computational capability of <img src="https://render.githubusercontent.com/render/math?math=10^{18}"> floating-point operations per second, and large-scale HPC scientific applications may generate vast volumes of data (several orders of magnitude larger than the available storage space) for post-anlaysis.  Moreover, runtime memory footprint and communication could be non-negligible bottlenecks of current HPC systems.

Tackling the big data reduction research requires expertise from computer science, mathematics, and application domains to study the problem holistically, and develop solutions and harden software tools that can be used by production applications. Specifically, the big-data computing community needs to understand a clear yet complex relationship between application design, data analysis and reduction methods, programming models, system software, hardware, and other elements of a next-generation large-scale computing infrastructure, especially given constraints on applicability, fidelity, performance portability, and energy efficiency. New data reduction techniques also need to be explored and developed continuously to suit emerging applications and diverse use cases.

There are at least three significant research topics that the community is striving to answer: (1) whether several orders of magnitude of data reduction is possible for extreme-scale sciences; (2) understanding the trade-off between the performance and accuracy of data reduction; and (3) solutions to effectively reduce data size while preserving the information inside the big datasets. 

The goal of this workshop is to provide a focused venue for researchers in all aspects of data reduction in all related communities to present their research results, exchange ideas, identify new research directions, and foster new collaborations within the community.

<em>Please note this yearâ€™s IEEE BigData conference and IWBDR workshop will be held **online**. Proceedings of the workshop will be published as planned. We will provide more details about how to attend this workshop virtually.</em>

# Submissions

### Topics of Interest

The focus areas for this workshop include, but are not limited to:

- Data reduction techniques for big data issues in _high-performance computing (HPC)_, _cloud computing_, _Internet-of-Things (IoT)_, _edge computing_, _machine learning and deep learning_, and other big data areas:
  - Lossy and lossless compression methods
  - Approximate computation methods
  - Compressive/compressed sensing methods
  - Tensor decomposition methods
  - Data deduplication methods
  - Domain-specific methods, e.g., structured/unstructured meshes, particles, tensors
  - Accuracy-guarantee data reduction methods
  - Optimal design of data reduction methods
- Data reduction challenges and solutions in observational and experimental environments
- Mathematical methods with robustly estimable or provable error bounds for both data and quantities of interest
- Metrics and infrastructures to evaluate reduction methods and assess quality/fidelity of reduced data
- Uncertainty quantification for reduction methods/models/representations
- Benchmark applications and datasets for big data reduction 
- Data analysis and visualization techniques leveraging reduced data
- Characterizing the impact of data reduction techniques on applications
- Hardware-software co-design of data reduction
- Trade-offs between accuracy and performance on emerging computing hardware and platforms
- Resource-constrained and/or time-constrained data reduction methods
- Software, tools, and programming models for managing reduced data
- Runtime systems and supports for data reduction
- Development of composable data reduction pipelines/workflows
- Automation of data reduction in scientific workflows
- Data reduction challenges and solutions in observational and experimental environments 

### Proceedings

All papers accepted for this workshop will be published in the Workshop Proceedings of IEEE Big Data Conference, made available in the IEEE eXplore digital library.

### Submission Instructions

* Camera-ready version of accepted papers must be compliant with the IEEE Xplore format for publication.
* Submissions must be in PDF format.
* Submissions are required to be within **6 pages** for short paper or **10 pages** for full paper (including references).
* Submissions must be single-spaced, 2-column pages in IEEE Xplore format.
* Submissions are NOT double-blind.
* Only web-based submissions are allowed.
* All submission deadlines are Anywhere on Earth (AOE).
* Please submit your paper via the submission system.
* Submission link: [Cyberchair submissions website](https://wi-lab.com/cyberchair/2023/bigdata23/scripts/submit.php?subarea=S38&undisplay_detail=1&wh=/cyberchair/2023/bigdata23/scripts/ws_submit.php).

### Important Dates

* Paper Submission: October 1, 2023
* Paper Acceptance Notification: November 1, 2023
* Camera-ready Deadline: November 20, 2023
* Workshop: December 15-18, 2023

# Organizers

### Program Chairs
* Kai Zhao, _University of Alabama at Birmingham_
* Sian Jin, _Temple University_
* Jieyang Chen, _University of Alabama at Birmingham_

### Web Chair
* Longtao Zhang, _University of Alabama at Birmingham_

### Steering Committee
* Dingwen Tao, _Indiana University_
* Sheng Di, _Argonne National Laboratory_
* Xin Liang, _University of Kentucky_

### Program Committee (Planned)

* William Godoy, _Oak Ridge National Laboratory_
* Pascal Grosset, _Los Alamos National Laboratory_
* Shaomeng Li, _National Center for Atmospheric Research_
* Xiaodong Yu, _Argonne National Laboratory_
* Jiannan Tian, _Indiana University_
* Chengshuo Xu, _University of California, Riverside_